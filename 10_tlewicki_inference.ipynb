{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover model, tokenizer and label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/anaconda3/envs/cmpe255/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model.h5')\n",
    "\n",
    "with open('tokenizer.json', 'rb') as f:\n",
    "    s = f.read()\n",
    "    t = keras.preprocessing.text.tokenizer_from_json(s)\n",
    "\n",
    "with open('label_encoder.pkl', 'rb') as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 64)           1920000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 250)           48250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                5020      \n",
      "=================================================================\n",
      "Total params: 2,036,020\n",
      "Trainable params: 2,036,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_would_say_that(s):\n",
    "    \"\"\"\n",
    "    s is a string of at least 100 words\n",
    "    returns prediction with the highest score\n",
    "    \"\"\"\n",
    "    if(len(s)<100): return None\n",
    "    seq = t.texts_to_sequences([s])[0][:100]\n",
    "    batch = np.zeros((64,100))\n",
    "    batch[0] = seq\n",
    "    scores = model.predict([batch], batch_size=1)\n",
    "    return le.inverse_transform([scores[0].argmax()])\n",
    "\n",
    "def classify(s):\n",
    "    \"\"\"\n",
    "    s is a string of at least 100 words\n",
    "    returns a dict in form of {'author': score}\n",
    "    \"\"\"\n",
    "    \n",
    "    if(len(s)<100): return None\n",
    "    seq = t.texts_to_sequences([s])[0][:100]\n",
    "    batch = np.zeros((64,100))\n",
    "    batch[0] = seq\n",
    "    scores = model.predict([batch], batch_size=1)\n",
    "    return {c: f\"{100 * round(scores[0][idx],4)} %\" for idx, c in enumerate(le.classes_)}\n",
    "\n",
    "def get_raw_scores(s):\n",
    "    \"\"\"\n",
    "    s is a string of at least 100 words\n",
    "    returns a dict in form of {'author': score}\n",
    "    \"\"\"\n",
    "    \n",
    "    if(len(s)<100): return None\n",
    "    seq = t.texts_to_sequences([s])[0][:100]\n",
    "    batch = np.zeros((64,100))\n",
    "    batch[0] = seq\n",
    "    scores = model.predict([batch], batch_size=1)\n",
    "    return {c: scores[0][idx] for idx, c in enumerate(le.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.cbc.ca/books/void-between-worlds-by-vaishnavi-jagadeeswaran-1.5149115\n",
    "shakespeare_style = \"\"\"\n",
    "O knaves embolden'd! Lend your ears to me,\n",
    "Of this foul gloom of mine be drawn towards, \n",
    "Let it be known, of its position poised\n",
    "This heart of mine, it looms darkly over, \n",
    "And stirs a grievous sadness now awake.\n",
    "\n",
    "Ethereal spires hath come aflame, alight!\n",
    "How burned by devilish industry; lo,\n",
    "The bells of brass and bronze sing sweet no more,\n",
    "For they lay silent, trapped within their tomb,\n",
    "Made quiet by the blaze, and wounded by the heat.\n",
    "\n",
    "How overwrought by grief, how sorrowful,\n",
    "Take flight, o soulless arch-villain so near,\n",
    "Be not a shroud lain over I, begone!\n",
    "\n",
    "And yet, o my Bertram, loved by me,\n",
    "He shirks his duty to grieve as all do. \n",
    "Share not with I does he my thoughts of it, \n",
    "Instead he goes about his work becalmed! \n",
    "Perhaps I ought to be assured he cares, \n",
    "And he has taken pains to becalm me.\n",
    "Yes, that is what he must be doing now,\n",
    "Adore his sweetly caring heart do I. \n",
    "\n",
    "Alack, for now I hear the choir song,\n",
    "Upon the cobblestones agleam with rain, \n",
    "They sing their words of God's forgiving grace, \n",
    "As all of Paris dreams and weeps as one, \n",
    "Awaiting news of our cathedral old,\n",
    "And what we all must do to aid our love.\n",
    "\"\"\"\n",
    "\n",
    "marlow = \"\"\"\n",
    "CHORUS. Not marching now in fields of Thrasymene,\n",
    "     Where Mars did mate1 the Carthaginians;\n",
    "     Nor sporting in the dalliance of love,\n",
    "     In courts of kings where state is overturn'd;\n",
    "     Nor in the pomp of proud audacious deeds,\n",
    "     Intends our Muse to vaunt2 her3 heavenly verse:\n",
    "     Only this, gentlemen,—we must perform\n",
    "     The form of Faustus' fortunes, good or bad:\n",
    "     To patient judgments we appeal our plaud,\n",
    "     And speak for Faustus in his infancy.\n",
    "     Now is he born, his parents base of stock,\n",
    "     In Germany, within a town call'd Rhodes:\n",
    "     Of riper years, to Wertenberg he went,\n",
    "     Whereas4 his kinsmen chiefly brought him up.\n",
    "     So soon he profits in divinity,\n",
    "     The fruitful plot of scholarism grac'd,\n",
    "     That shortly he was grac'd with doctor's name,\n",
    "     Excelling all whose sweet delight disputes\n",
    "     In heavenly matters of theology;\n",
    "     Till swoln with cunning,5 of a self-conceit,\n",
    "     His waxen wings did mount above his reach,\n",
    "     And, melting, heavens conspir'd his overthrow;\n",
    "     For, falling to a devilish exercise,\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "actual_dickens = \"\"\"\n",
    "An aunt of my father’s, and consequently a great-aunt of mine, of whom\n",
    "I shall have more to relate by and by, was the principal magnate of our\n",
    "family. Miss Trotwood, or Miss Betsey, as my poor mother always called\n",
    "her, when she sufficiently overcame her dread of this formidable\n",
    "personage to mention her at all (which was seldom), had been married\n",
    "to a husband younger than herself, who was very handsome, except in the\n",
    "sense of the homely adage, ‘handsome is, that handsome does’--for he\n",
    "was strongly suspected of having beaten Miss Betsey, and even of having once,\n",
    "on a disputed question of supplies, made some hasty but determined\n",
    "arrangements to throw her out of a two pair of stairs’ window\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shakespeare, William'], dtype='<U35')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_shakespeare = \"\"\"To be, or not to be: that is the question: Whether 'tis nobler in the mind to suffer The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles, And by opposing end them? To die: to sleep; No more; and by a sleep to say we end The heart-ache and the thousand natural shocks That flesh is heir to, 'tis a consummation Devoutly to be wish'd. To die, to sleep; To sleep: perchance to dream: ay, there's the rub; For in that sleep of death what dreams may come When we have shuffled off this mortal coil, Must give us pause: there's the respect That makes calamity of so long life; For who would bear the whips and scorns of time, The oppressor's wrong, the proud man's contumely, The pangs of despised love, the law's delay,\"\"\"\n",
    "who_would_say_that(actual_shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donald Trump's latest tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alger, Horatio, Jr.': '0.0 %',\n",
       " 'Ballantyne, R. M. (Robert Michael)': '0.0 %',\n",
       " 'Balzac, Honoré de': '0.0 %',\n",
       " 'Dickens, Charles': '0.0 %',\n",
       " 'Ebers, Georg': '0.0 %',\n",
       " 'Fenn, George Manville': '0.0 %',\n",
       " 'Hawthorne, Nathaniel': '0.0 %',\n",
       " 'Henty, G. A. (George Alfred)': '0.0 %',\n",
       " 'Howells, William Dean': '0.0 %',\n",
       " 'Jacobs, W. W. (William Wymark)': '0.0 %',\n",
       " 'Kingston, William Henry Giles': '0.0 %',\n",
       " 'Lytton, Edward Bulwer Lytton, Baron': '0.0 %',\n",
       " 'Meredith, George': '0.0 %',\n",
       " 'Motley, John Lothrop': '0.0 %',\n",
       " 'Oliphant, Mrs. (Margaret)': '0.0 %',\n",
       " 'Parker, Gilbert': '0.0 %',\n",
       " 'Pepys, Samuel': '0.0 %',\n",
       " 'Shakespeare, William': '0.0 %',\n",
       " 'Stevenson, Robert Louis': '0.0 %',\n",
       " 'Twain, Mark': '0.0 %'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realdonaldtrump = \"\"\"The White House CoronaVirus Task Force, headed by Vice President Mike Pence, has done a fantastic job of bringing together vast highly complex resources that have set a high standard for others to follow in the future. Ventilators, which were few & in bad shape, are now being produced in the thousands, and we have many to spare. We are helping other countries which are desperate for them. Likewise, after having been left little, we are now doing more testing than all other countries combined, and with superior tests. Face masks & shields, gloves, gowns etc. are now plentiful. The last four Governors teleconference calls have been conclusively strong. Because of this success, the Task Force will continue on indefinitely with its focus on SAFETY & OPENING UP OUR COUNTRY AGAIN. We may add or subtract people to it, as appropriate. The Task Force will also be very focused on Vaccines & Therapeutics. Thank you!\"\"\"\n",
    "get_percentages(realdonaldtrump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Christopher Marlowe\n",
    "Not in the datset, but __very__ close to Shakespeare (same era, similar style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shakespeare, William'], dtype='<U35')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marlowe = \"\"\"\n",
    "CHORUS. Not marching now in fields of Thrasymene,\n",
    "     Where Mars did mate1 the Carthaginians;\n",
    "     Nor sporting in the dalliance of love,\n",
    "     In courts of kings where state is overturn'd;\n",
    "     Nor in the pomp of proud audacious deeds,\n",
    "     Intends our Muse to vaunt2 her3 heavenly verse:\n",
    "     Only this, gentlemen,—we must perform\n",
    "     The form of Faustus' fortunes, good or bad:\n",
    "     To patient judgments we appeal our plaud,\n",
    "     And speak for Faustus in his infancy.\n",
    "     Now is he born, his parents base of stock,\n",
    "     In Germany, within a town call'd Rhodes:\n",
    "     Of riper years, to Wertenberg he went,\n",
    "     Whereas4 his kinsmen chiefly brought him up.\n",
    "     So soon he profits in divinity,\n",
    "     The fruitful plot of scholarism \n",
    "\"\"\"\n",
    "\n",
    "who_would_say_that(marlowe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alger, Horatio, Jr.': '0.0 %',\n",
       " 'Ballantyne, R. M. (Robert Michael)': '0.0 %',\n",
       " 'Balzac, Honoré de': '0.0 %',\n",
       " 'Dickens, Charles': '0.0 %',\n",
       " 'Ebers, Georg': '0.0 %',\n",
       " 'Fenn, George Manville': '0.0 %',\n",
       " 'Hawthorne, Nathaniel': '0.0 %',\n",
       " 'Henty, G. A. (George Alfred)': '0.0 %',\n",
       " 'Howells, William Dean': '0.0 %',\n",
       " 'Jacobs, W. W. (William Wymark)': '0.0 %',\n",
       " 'Kingston, William Henry Giles': '0.0 %',\n",
       " 'Lytton, Edward Bulwer Lytton, Baron': '0.0 %',\n",
       " 'Meredith, George': '0.0 %',\n",
       " 'Motley, John Lothrop': '0.0 %',\n",
       " 'Oliphant, Mrs. (Margaret)': '0.0 %',\n",
       " 'Parker, Gilbert': '0.0 %',\n",
       " 'Pepys, Samuel': '0.0 %',\n",
       " 'Shakespeare, William': '100.0 %',\n",
       " 'Stevenson, Robert Louis': '0.0 %',\n",
       " 'Twain, Mark': '0.0 %'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_percentages(marlowe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_style_competition = \"\"\"\n",
    "O knaves embolden'd! Lend your ears to me,\n",
    "Of this foul gloom of mine be drawn towards, \n",
    "Let it be known, of its position poised\n",
    "This heart of mine, it looms darkly over, \n",
    "And stirs a grievous sadness now awake.\n",
    "\n",
    "Ethereal spires hath come aflame, alight!\n",
    "How burned by devilish industry; lo,\n",
    "The bells of brass and bronze sing sweet no more,\n",
    "For they lay silent, trapped within their tomb,\n",
    "Made quiet by the blaze, and wounded by the heat.\n",
    "\n",
    "How overwrought by grief, how sorrowful,\n",
    "Take flight, o soulless arch-villain so near,\n",
    "Be not a shroud lain over I, begone!\n",
    "\n",
    "And yet, o my Bertram, loved by me,\n",
    "He shirks his duty to grieve as all do. \n",
    "Share not with I does he my thoughts of it, \n",
    "Instead he goes about his work becalmed! \n",
    "Perhaps I ought to be assured he cares, \n",
    "And he has taken pains to becalm me.\n",
    "Yes, that is what he must be doing now,\n",
    "Adore his sweetly caring heart do I. \n",
    "\n",
    "Alack, for now I hear the choir song,\n",
    "Upon the cobblestones agleam with rain, \n",
    "They sing their words of God's forgiving grace, \n",
    "As all of Paris dreams and weeps as one, \n",
    "Awaiting news of our cathedral old,\n",
    "And what we all must do to aid our love.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "255-data-mining",
   "language": "python",
   "name": "255-data-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
