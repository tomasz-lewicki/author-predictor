{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Mining",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomek-l/video-mining/blob/master/Video_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dPVSb2ZOhx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-jdH6Z8hJn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ed946fb7-2bf6-405a-e8c1-219872a641ef"
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Move channel axes - go from (N,H,W,C) convention to (N,C,H,W)\n",
        "X_train = np.moveaxis(X_train, 3, 1)\n",
        "X_test = np.moveaxis(X_test, 3, 1)\n",
        "\n",
        "# Convert Feature Vectors to FP32\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "y_train = y_train.astype(np.int)\n",
        "y_test = y_test.astype(np.int)\n",
        "\n",
        "y_train = np.squeeze(y_train)\n",
        "y_test = np.squeeze(y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4EO71auOqdC",
        "colab_type": "code",
        "outputId": "14349509-4ee7-496c-f79a-264650235b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaku1svfvQC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        " \n",
        "class CIFAR10_custom_ds(Dataset):\n",
        "    def __init__(self, feature_vec, labels, device):\n",
        "        self._device = device\n",
        "        self.x = feature_vec\n",
        "        self.y = labels \n",
        "\n",
        "        # I only do eager conversion to CUDA memory since CIFAR10 is relatively small\n",
        "        # (will only take some ~200MB of memory)\n",
        "        self.x = torch.tensor(self.x).to(self._device)\n",
        "        self.y = torch.tensor(self.y).to(self._device)\n",
        "         \n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtzZDhjlR0T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch way to use CIFAR-10\n",
        "# (with DataLoader class)\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "#                                         download=True, transform=transform)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "#                                        download=True, transform=transform)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "#                                          shuffle=False, num_workers=2)\n",
        "\n",
        "# classes = ('plane', 'car', 'bird', 'cat',\n",
        "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKqKBwaLSDFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Let's define a simple NN based of resnet18\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.backbone = models.resnet18(pretrained=False)\n",
        "        self.backbone.fc = torch.nn.Linear(512, n_classes)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX-7_NAU0KYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# import torch.multiprocessing as mp\n",
        "# try:\n",
        "#     mp.set_start_method(\"spawn\")\n",
        "# except RuntimeError as e:\n",
        "#     print(e)\n",
        "#     pass\n",
        "\n",
        "GPU = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "trainset = CIFAR10_custom_ds(X_train, y_train, GPU)\n",
        "assert trainset[0:4] \n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZi1-GvGTrL6",
        "colab_type": "code",
        "outputId": "cd27ea94-7746-4544-d838-5918ea1abde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch import optim \n",
        "\n",
        "net = Net(10).to(GPU)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "print_every = 100\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every-1:    # print every 100 mini-batches\n",
        "            print(f'epoch {epoch+1} batch {i+1} loss: {(running_loss / print_every):.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch 100 loss: 2.2282\n",
            "epoch 1 batch 200 loss: 2.1144\n",
            "epoch 1 batch 300 loss: 2.0518\n",
            "epoch 1 batch 400 loss: 2.0111\n",
            "epoch 1 batch 500 loss: 1.9868\n",
            "epoch 1 batch 600 loss: 1.9710\n",
            "epoch 1 batch 700 loss: 1.9514\n",
            "epoch 2 batch 100 loss: 1.9158\n",
            "epoch 2 batch 200 loss: 1.9051\n",
            "epoch 2 batch 300 loss: 1.9037\n",
            "epoch 2 batch 400 loss: 1.8992\n",
            "epoch 2 batch 500 loss: 1.8843\n",
            "epoch 2 batch 600 loss: 1.8871\n",
            "epoch 2 batch 700 loss: 1.8846\n",
            "epoch 3 batch 100 loss: 1.8629\n",
            "epoch 3 batch 200 loss: 1.8601\n",
            "epoch 3 batch 300 loss: 1.8578\n",
            "epoch 3 batch 400 loss: 1.8502\n",
            "epoch 3 batch 500 loss: 1.8462\n",
            "epoch 3 batch 600 loss: 1.8485\n",
            "epoch 3 batch 700 loss: 1.8417\n",
            "epoch 4 batch 100 loss: 1.8251\n",
            "epoch 4 batch 200 loss: 1.8209\n",
            "epoch 4 batch 300 loss: 1.8215\n",
            "epoch 4 batch 400 loss: 1.8232\n",
            "epoch 4 batch 500 loss: 1.8125\n",
            "epoch 4 batch 600 loss: 1.8209\n",
            "epoch 4 batch 700 loss: 1.8151\n",
            "epoch 5 batch 100 loss: 1.7934\n",
            "epoch 5 batch 200 loss: 1.7891\n",
            "epoch 5 batch 300 loss: 1.7919\n",
            "epoch 5 batch 400 loss: 1.7904\n",
            "epoch 5 batch 500 loss: 1.7924\n",
            "epoch 5 batch 600 loss: 1.7884\n",
            "epoch 5 batch 700 loss: 1.7883\n",
            "epoch 6 batch 100 loss: 1.7640\n",
            "epoch 6 batch 200 loss: 1.7722\n",
            "epoch 6 batch 300 loss: 1.7692\n",
            "epoch 6 batch 400 loss: 1.7697\n",
            "epoch 6 batch 500 loss: 1.7657\n",
            "epoch 6 batch 600 loss: 1.7637\n",
            "epoch 6 batch 700 loss: 1.7658\n",
            "epoch 7 batch 100 loss: 1.7470\n",
            "epoch 7 batch 200 loss: 1.7470\n",
            "epoch 7 batch 300 loss: 1.7447\n",
            "epoch 7 batch 400 loss: 1.7383\n",
            "epoch 7 batch 500 loss: 1.7447\n",
            "epoch 7 batch 600 loss: 1.7546\n",
            "epoch 7 batch 700 loss: 1.7496\n",
            "epoch 8 batch 100 loss: 1.7217\n",
            "epoch 8 batch 200 loss: 1.7174\n",
            "epoch 8 batch 300 loss: 1.7180\n",
            "epoch 8 batch 400 loss: 1.7258\n",
            "epoch 8 batch 500 loss: 1.7299\n",
            "epoch 8 batch 600 loss: 1.7259\n",
            "epoch 8 batch 700 loss: 1.7277\n",
            "epoch 9 batch 100 loss: 1.7015\n",
            "epoch 9 batch 200 loss: 1.6999\n",
            "epoch 9 batch 300 loss: 1.7016\n",
            "epoch 9 batch 400 loss: 1.7084\n",
            "epoch 9 batch 500 loss: 1.7062\n",
            "epoch 9 batch 600 loss: 1.7145\n",
            "epoch 9 batch 700 loss: 1.7114\n",
            "epoch 10 batch 100 loss: 1.6836\n",
            "epoch 10 batch 200 loss: 1.6852\n",
            "epoch 10 batch 300 loss: 1.6914\n",
            "epoch 10 batch 400 loss: 1.6796\n",
            "epoch 10 batch 500 loss: 1.6903\n",
            "epoch 10 batch 600 loss: 1.6915\n",
            "epoch 10 batch 700 loss: 1.6975\n",
            "epoch 11 batch 100 loss: 1.6739\n",
            "epoch 11 batch 200 loss: 1.6630\n",
            "epoch 11 batch 300 loss: 1.6805\n",
            "epoch 11 batch 400 loss: 1.6738\n",
            "epoch 11 batch 500 loss: 1.6793\n",
            "epoch 11 batch 600 loss: 1.6674\n",
            "epoch 11 batch 700 loss: 1.6688\n",
            "epoch 12 batch 100 loss: 1.6486\n",
            "epoch 12 batch 200 loss: 1.6507\n",
            "epoch 12 batch 300 loss: 1.6577\n",
            "epoch 12 batch 400 loss: 1.6594\n",
            "epoch 12 batch 500 loss: 1.6535\n",
            "epoch 12 batch 600 loss: 1.6560\n",
            "epoch 12 batch 700 loss: 1.6632\n",
            "epoch 13 batch 100 loss: 1.6444\n",
            "epoch 13 batch 200 loss: 1.6466\n",
            "epoch 13 batch 300 loss: 1.6433\n",
            "epoch 13 batch 400 loss: 1.6465\n",
            "epoch 13 batch 500 loss: 1.6476\n",
            "epoch 13 batch 600 loss: 1.6423\n",
            "epoch 13 batch 700 loss: 1.6454\n",
            "epoch 14 batch 100 loss: 1.6269\n",
            "epoch 14 batch 200 loss: 1.6255\n",
            "epoch 14 batch 300 loss: 1.6291\n",
            "epoch 14 batch 400 loss: 1.6335\n",
            "epoch 14 batch 500 loss: 1.6298\n",
            "epoch 14 batch 600 loss: 1.6282\n",
            "epoch 14 batch 700 loss: 1.6287\n",
            "epoch 15 batch 100 loss: 1.6102\n",
            "epoch 15 batch 200 loss: 1.6152\n",
            "epoch 15 batch 300 loss: 1.6119\n",
            "epoch 15 batch 400 loss: 1.6157\n",
            "epoch 15 batch 500 loss: 1.6221\n",
            "epoch 15 batch 600 loss: 1.6215\n",
            "epoch 15 batch 700 loss: 1.6201\n",
            "epoch 16 batch 100 loss: 1.6030\n",
            "epoch 16 batch 200 loss: 1.6053\n",
            "epoch 16 batch 300 loss: 1.6022\n",
            "epoch 16 batch 400 loss: 1.6042\n",
            "epoch 16 batch 500 loss: 1.6068\n",
            "epoch 16 batch 600 loss: 1.6086\n",
            "epoch 16 batch 700 loss: 1.6131\n",
            "epoch 17 batch 100 loss: 1.5940\n",
            "epoch 17 batch 200 loss: 1.5916\n",
            "epoch 17 batch 300 loss: 1.5942\n",
            "epoch 17 batch 400 loss: 1.5898\n",
            "epoch 17 batch 500 loss: 1.5989\n",
            "epoch 17 batch 600 loss: 1.6001\n",
            "epoch 17 batch 700 loss: 1.6003\n",
            "epoch 18 batch 100 loss: 1.5865\n",
            "epoch 18 batch 200 loss: 1.5813\n",
            "epoch 18 batch 300 loss: 1.5821\n",
            "epoch 18 batch 400 loss: 1.5936\n",
            "epoch 18 batch 500 loss: 1.5829\n",
            "epoch 18 batch 600 loss: 1.5822\n",
            "epoch 18 batch 700 loss: 1.5906\n",
            "epoch 19 batch 100 loss: 1.5721\n",
            "epoch 19 batch 200 loss: 1.5804\n",
            "epoch 19 batch 300 loss: 1.5763\n",
            "epoch 19 batch 400 loss: 1.5782\n",
            "epoch 19 batch 500 loss: 1.5776\n",
            "epoch 19 batch 600 loss: 1.5821\n",
            "epoch 19 batch 700 loss: 1.5818\n",
            "epoch 20 batch 100 loss: 1.5721\n",
            "epoch 20 batch 200 loss: 1.5656\n",
            "epoch 20 batch 300 loss: 1.5689\n",
            "epoch 20 batch 400 loss: 1.5638\n",
            "epoch 20 batch 500 loss: 1.5726\n",
            "epoch 20 batch 600 loss: 1.5759\n",
            "epoch 20 batch 700 loss: 1.5780\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql1vOS_HM_g6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d9dde73-f6b2-4c7e-dee5-86e1947af20c"
      },
      "source": [
        "testset = CIFAR10_custom_ds(X_test, y_test, GPU)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the  {len(y_test)} test images is {100 * correct / total} %')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the  10000 test images is 62.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvNzWn0lM63F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = CIFAR10_custom_ds(X_train[:10000], y_train[:10000], GPU)\n",
        "assert trainset[0:4] \n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE2UzlWROTvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "1b89abdd-5988-4a33-a1be-f9913d739b2a"
      },
      "source": [
        "from torch import optim \n",
        "\n",
        "net_small = Net(10).to(GPU)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_small.parameters(), lr=0.001, momentum=0.9)\n",
        "print_every = 100\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net_small(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every-1:    # print every 100 mini-batches\n",
        "            print(f'epoch {epoch+1} batch {i+1} loss: {(running_loss / print_every):.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch 100 loss: 2.2341\n",
            "epoch 2 batch 100 loss: 2.0524\n",
            "epoch 3 batch 100 loss: 1.9779\n",
            "epoch 4 batch 100 loss: 1.9228\n",
            "epoch 5 batch 100 loss: 1.8896\n",
            "epoch 6 batch 100 loss: 1.8490\n",
            "epoch 7 batch 100 loss: 1.8268\n",
            "epoch 8 batch 100 loss: 1.7940\n",
            "epoch 9 batch 100 loss: 1.7714\n",
            "epoch 10 batch 100 loss: 1.7443\n",
            "epoch 11 batch 100 loss: 1.7289\n",
            "epoch 12 batch 100 loss: 1.7046\n",
            "epoch 13 batch 100 loss: 1.6881\n",
            "epoch 14 batch 100 loss: 1.6686\n",
            "epoch 15 batch 100 loss: 1.6514\n",
            "epoch 16 batch 100 loss: 1.6365\n",
            "epoch 17 batch 100 loss: 1.6217\n",
            "epoch 18 batch 100 loss: 1.6060\n",
            "epoch 19 batch 100 loss: 1.5958\n",
            "epoch 20 batch 100 loss: 1.5874\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lz9tDL1PIr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e85e697-ab0e-4ab9-ce19-73a3db4172e5"
      },
      "source": [
        "testset = CIFAR10_custom_ds(X_test, y_test, GPU)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net_small(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the  {len(y_test)} test images is {100 * correct / total} %')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the  10000 test images is 46.66 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNkLtu9xd9_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = CIFAR10_custom_ds(X_train[:20000], y_train[:20000], GPU)\n",
        "assert trainset[0:4] \n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwBS5ij0Nw-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67dfd43f-b29a-4408-e710-cb4bcdf66ff8"
      },
      "source": [
        "from torch import optim \n",
        "\n",
        "net_random = Net(10).to(GPU)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_random.parameters(), lr=0.001, momentum=0.9)\n",
        "print_every = 100\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net_random(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every-1:    # print every 100 mini-batches\n",
        "            print(f'epoch {epoch+1} batch {i+1} loss: {(running_loss / print_every):.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch 100 loss: 2.2281\n",
            "epoch 1 batch 200 loss: 2.1055\n",
            "epoch 1 batch 300 loss: 2.0514\n",
            "epoch 2 batch 100 loss: 1.9960\n",
            "epoch 2 batch 200 loss: 1.9796\n",
            "epoch 2 batch 300 loss: 1.9518\n",
            "epoch 3 batch 100 loss: 1.9238\n",
            "epoch 3 batch 200 loss: 1.9164\n",
            "epoch 3 batch 300 loss: 1.9044\n",
            "epoch 4 batch 100 loss: 1.8794\n",
            "epoch 4 batch 200 loss: 1.8786\n",
            "epoch 4 batch 300 loss: 1.8740\n",
            "epoch 5 batch 100 loss: 1.8481\n",
            "epoch 5 batch 200 loss: 1.8495\n",
            "epoch 5 batch 300 loss: 1.8466\n",
            "epoch 6 batch 100 loss: 1.8235\n",
            "epoch 6 batch 200 loss: 1.8245\n",
            "epoch 6 batch 300 loss: 1.8247\n",
            "epoch 7 batch 100 loss: 1.7969\n",
            "epoch 7 batch 200 loss: 1.8011\n",
            "epoch 7 batch 300 loss: 1.7956\n",
            "epoch 8 batch 100 loss: 1.7758\n",
            "epoch 8 batch 200 loss: 1.7786\n",
            "epoch 8 batch 300 loss: 1.7747\n",
            "epoch 9 batch 100 loss: 1.7516\n",
            "epoch 9 batch 200 loss: 1.7544\n",
            "epoch 9 batch 300 loss: 1.7536\n",
            "epoch 10 batch 100 loss: 1.7387\n",
            "epoch 10 batch 200 loss: 1.7313\n",
            "epoch 10 batch 300 loss: 1.7325\n",
            "epoch 11 batch 100 loss: 1.7138\n",
            "epoch 11 batch 200 loss: 1.7104\n",
            "epoch 11 batch 300 loss: 1.7150\n",
            "epoch 12 batch 100 loss: 1.6938\n",
            "epoch 12 batch 200 loss: 1.6925\n",
            "epoch 12 batch 300 loss: 1.6985\n",
            "epoch 13 batch 100 loss: 1.6745\n",
            "epoch 13 batch 200 loss: 1.6793\n",
            "epoch 13 batch 300 loss: 1.6762\n",
            "epoch 14 batch 100 loss: 1.6578\n",
            "epoch 14 batch 200 loss: 1.6637\n",
            "epoch 14 batch 300 loss: 1.6606\n",
            "epoch 15 batch 100 loss: 1.6409\n",
            "epoch 15 batch 200 loss: 1.6388\n",
            "epoch 15 batch 300 loss: 1.6503\n",
            "epoch 16 batch 100 loss: 1.6244\n",
            "epoch 16 batch 200 loss: 1.6317\n",
            "epoch 16 batch 300 loss: 1.6296\n",
            "epoch 17 batch 100 loss: 1.6118\n",
            "epoch 17 batch 200 loss: 1.6152\n",
            "epoch 17 batch 300 loss: 1.6169\n",
            "epoch 18 batch 100 loss: 1.5977\n",
            "epoch 18 batch 200 loss: 1.6028\n",
            "epoch 18 batch 300 loss: 1.6081\n",
            "epoch 19 batch 100 loss: 1.5863\n",
            "epoch 19 batch 200 loss: 1.5948\n",
            "epoch 19 batch 300 loss: 1.5939\n",
            "epoch 20 batch 100 loss: 1.5754\n",
            "epoch 20 batch 200 loss: 1.5804\n",
            "epoch 20 batch 300 loss: 1.5888\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHlX7VOSQpXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9953fe4b-575d-412e-af91-271c6a39269f"
      },
      "source": [
        "testset = CIFAR10_custom_ds(X_test, y_test, GPU)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net_random(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the  {len(y_test)} test images is {100 * correct / total} %')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the  10000 test images is 54.07 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ob4vjjiR1t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics.euc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqR3TcbMSSg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2f73ac3-ec1e-45b6-9927-e2069afef02e"
      },
      "source": [
        ".shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 3072)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYVMxaD6QPnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "X_baseline = X_train[:10000]\n",
        "X_to_sample = X_train[10000:]\n",
        "\n",
        "dist = metrics.euclidean_distances(X_baseline.reshape(10000, -1).squeeze(), X_to_sample.reshape(40000, -1).squeeze())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hMbovFlSnB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sort_idx = np.argsort(dist.sum(axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA-kbU8NTQJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "our_pick = sort_idx[-10000:] # we pick thees to append X_baseline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw8U9bpgTlxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = np.concatenate([X_baseline, X_to_sample[our_pick]], axis=0)\n",
        "y_new = np.concatenate([y_train[:10000], y_train[10000:][our_pick]], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtI2spQaQGal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = CIFAR10_custom_ds(X_new, y_new, GPU)\n",
        "assert trainset[0:4] \n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmkzWRkVUCJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49ec6441-d8f5-41fd-d667-bec467b46767"
      },
      "source": [
        "from torch import optim \n",
        "\n",
        "net_l2 = Net(10).to(GPU)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net_l2.parameters(), lr=0.001, momentum=0.9)\n",
        "print_every = 100\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net_l2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % print_every == print_every-1:    # print every 100 mini-batches\n",
        "            print(f'epoch {epoch+1} batch {i+1} loss: {(running_loss / print_every):.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 batch 100 loss: 2.2312\n",
            "epoch 1 batch 200 loss: 2.1214\n",
            "epoch 1 batch 300 loss: 2.0528\n",
            "epoch 2 batch 100 loss: 1.9960\n",
            "epoch 2 batch 200 loss: 1.9740\n",
            "epoch 2 batch 300 loss: 1.9526\n",
            "epoch 3 batch 100 loss: 1.9170\n",
            "epoch 3 batch 200 loss: 1.9108\n",
            "epoch 3 batch 300 loss: 1.9022\n",
            "epoch 4 batch 100 loss: 1.8726\n",
            "epoch 4 batch 200 loss: 1.8694\n",
            "epoch 4 batch 300 loss: 1.8695\n",
            "epoch 5 batch 100 loss: 1.8403\n",
            "epoch 5 batch 200 loss: 1.8441\n",
            "epoch 5 batch 300 loss: 1.8406\n",
            "epoch 6 batch 100 loss: 1.8111\n",
            "epoch 6 batch 200 loss: 1.8159\n",
            "epoch 6 batch 300 loss: 1.8122\n",
            "epoch 7 batch 100 loss: 1.7864\n",
            "epoch 7 batch 200 loss: 1.7912\n",
            "epoch 7 batch 300 loss: 1.7900\n",
            "epoch 8 batch 100 loss: 1.7666\n",
            "epoch 8 batch 200 loss: 1.7704\n",
            "epoch 8 batch 300 loss: 1.7729\n",
            "epoch 9 batch 100 loss: 1.7469\n",
            "epoch 9 batch 200 loss: 1.7457\n",
            "epoch 9 batch 300 loss: 1.7475\n",
            "epoch 10 batch 100 loss: 1.7245\n",
            "epoch 10 batch 200 loss: 1.7277\n",
            "epoch 10 batch 300 loss: 1.7301\n",
            "epoch 11 batch 100 loss: 1.7068\n",
            "epoch 11 batch 200 loss: 1.7079\n",
            "epoch 11 batch 300 loss: 1.7078\n",
            "epoch 12 batch 100 loss: 1.6796\n",
            "epoch 12 batch 200 loss: 1.6919\n",
            "epoch 12 batch 300 loss: 1.6972\n",
            "epoch 13 batch 100 loss: 1.6674\n",
            "epoch 13 batch 200 loss: 1.6733\n",
            "epoch 13 batch 300 loss: 1.6673\n",
            "epoch 14 batch 100 loss: 1.6545\n",
            "epoch 14 batch 200 loss: 1.6512\n",
            "epoch 14 batch 300 loss: 1.6589\n",
            "epoch 15 batch 100 loss: 1.6328\n",
            "epoch 15 batch 200 loss: 1.6381\n",
            "epoch 15 batch 300 loss: 1.6462\n",
            "epoch 16 batch 100 loss: 1.6228\n",
            "epoch 16 batch 200 loss: 1.6226\n",
            "epoch 16 batch 300 loss: 1.6304\n",
            "epoch 17 batch 100 loss: 1.6138\n",
            "epoch 17 batch 200 loss: 1.6137\n",
            "epoch 17 batch 300 loss: 1.6105\n",
            "epoch 18 batch 100 loss: 1.5976\n",
            "epoch 18 batch 200 loss: 1.6057\n",
            "epoch 18 batch 300 loss: 1.6076\n",
            "epoch 19 batch 100 loss: 1.5870\n",
            "epoch 19 batch 200 loss: 1.5921\n",
            "epoch 19 batch 300 loss: 1.5995\n",
            "epoch 20 batch 100 loss: 1.5787\n",
            "epoch 20 batch 200 loss: 1.5827\n",
            "epoch 20 batch 300 loss: 1.5869\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwPgSDgUB4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10390a97-e669-4622-a750-646af5171fcf"
      },
      "source": [
        "testset = CIFAR10_custom_ds(X_test, y_test, GPU)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net_l2(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the  {len(y_test)} test images is {100 * correct / total} %')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the  10000 test images is 52.32 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jenzRJxSWKVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4164cbdc-03a3-4d34-a67a-1999ba9a9185"
      },
      "source": [
        "np.argsort(dist[:,0])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 521, 6965, 3949, ..., 5867, 6400, 9522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH8GuNgyWtYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "19dd06a2-99e5-4edf-d290-28a3c40efe80"
      },
      "source": [
        "plt.imshow(np.rollaxis(X_to_sample[0], 0, 3).astype(np.uint8))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6fb151a748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8BMW1X6X2JB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a8d79ec8-f7cf-4752-b70b-26050379e8ff"
      },
      "source": [
        "plt.imshow(np.rollaxis(X_baseline[521], 0, 3).astype(np.uint8))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6fb14fa320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Y7gOGYX_U6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6ad403af-8863-4dbe-ea6f-c576b41bc66a"
      },
      "source": [
        "plt.imshow(np.rollaxis(X_baseline[9522], 0, 3).astype(np.uint8))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6fb1398b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}